{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aicua_SR - Symbolic Regression Training on GPU\n",
    "\n",
    "Train PySR models on Kaggle GPU for faster formula discovery.\n",
    "\n",
    "## Setup\n",
    "1. Enable GPU: Settings → Accelerator → GPU P100/T4\n",
    "2. Clone Aicua_SR repo from GitHub\n",
    "3. Run training cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Aicua_SR repository\n",
    "!git clone https://github.com/Aicua/Aicua_SR.git\n",
    "%cd Aicua_SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install pysr pandas numpy sympy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate datasets (v2/v4 - latest versions)\n!python scripts/generate_petal_spline_v2.py\n!python scripts/generate_bone_rigging_v4.py\n!python scripts/generate_cot_dataset.py"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load petal spline v2 dataset (middle-wide shape, ultra-thin)\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('data/processed/petal_spline_v2.csv')\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\nprint(f\"\\nDataset statistics:\")\nprint(f\"  base_size range: {df['base_size'].min():.2f} - {df['base_size'].max():.2f}\")\nprint(f\"  petal_height (cp3_y) range: {df['cp3_y'].min():.4f} - {df['cp3_y'].max():.4f}\")\nmid_width = df['cp4_x'] - df['cp2_x']\nbase_width = df['cp5_x'] - df['cp1_x']\nprint(f\"  Mid/Base ratio: {(mid_width / base_width).mean():.2f} (should be ~2.0)\")\nprint(f\"  Thickness/Height ratio: {(df['extrude_depth'] / df['cp3_y']).mean():.4f} (ultra-thin)\")\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Real PySR Training - Petal Spline Control Points (V2)\nfrom pysr import PySRRegressor\n\n# Features (v2 naming)\nfeatures = ['base_size', 'layer_index', 'petal_index', 'opening_degree']\nX = df[features].values\n\n# Train model for cp3_y (petal height) - most important parameter\ny = df['cp3_y'].values\n\nmodel = PySRRegressor(\n    niterations=100,  # Increase for better results (GPU handles this fast)\n    binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n    unary_operators=[\"sqrt\", \"square\", \"sin\", \"cos\"],\n    populations=20,\n    population_size=50,\n    maxsize=25,\n    ncyclesperiteration=200,\n    parsimony=0.001,  # Prefer simpler formulas\n    model_selection=\"best\",\n    verbosity=1,\n)\n\nprint(\"Training SR model for cp3_y (petal height)...\")\nmodel.fit(X, y, variable_names=features)\n\nprint(f\"\\nBest equation for cp3_y:\")\nprint(model.sympy())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all discovered equations\n",
    "print(\"All equations (sorted by complexity):\")\n",
    "print(model)\n",
    "\n",
    "# Latex format\n",
    "print(f\"\\nLatex: {model.latex()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train models for all control points (V2)\ntargets = ['cp1_x', 'cp1_y', 'cp2_x', 'cp2_y', 'cp3_x', 'cp3_y', \n           'cp4_x', 'cp4_y', 'cp5_x', 'cp5_y', 'extrude_depth']\n\ndiscovered_formulas = {}\n\nfor target in targets:\n    print(f\"\\n{'='*60}\")\n    print(f\"Training model for: {target}\")\n    print(f\"{'='*60}\")\n    \n    y = df[target].values\n    \n    model = PySRRegressor(\n        niterations=50,  # Faster for demo, increase for production\n        binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n        unary_operators=[\"sqrt\", \"square\"],\n        populations=10,\n        population_size=30,\n        maxsize=20,\n        parsimony=0.002,\n        model_selection=\"best\",\n        verbosity=0,\n    )\n    \n    model.fit(X, y, variable_names=features)\n    \n    formula = str(model.sympy())\n    discovered_formulas[target] = formula\n    \n    print(f\"✓ {target} = {formula}\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"All discovered formulas for petal_spline_v2:\")\nprint(f\"{'='*60}\")\nfor target, formula in discovered_formulas.items():\n    print(f\"{target} = {formula}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save discovered formulas to JSON\n",
    "import json\n",
    "\n",
    "with open('data/generated/sr_discovered_formulas.json', 'w') as f:\n",
    "    json.dump(discovered_formulas, f, indent=2)\n",
    "\n",
    "print(\"✓ Saved formulas to data/generated/sr_discovered_formulas.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate Python code from discovered formulas (V2)\ndef formula_to_python(formula_str, target_name):\n    \"\"\"Convert SymPy formula to Python function.\"\"\"\n    # Replace variable names (v2 naming)\n    code = formula_str\n    code = code.replace('base_size', 'x0')\n    code = code.replace('layer_index', 'x1')\n    code = code.replace('petal_index', 'x2')\n    code = code.replace('opening_degree', 'x3')\n    \n    # Replace math functions\n    code = code.replace('sqrt', 'math.sqrt')\n    code = code.replace('sin', 'math.sin')\n    code = code.replace('cos', 'math.cos')\n    code = code.replace('square', 'lambda x: x**2')\n    \n    func_code = f\"\"\"\ndef compute_{target_name}(base_size, layer_index, petal_index, opening_degree):\n    \\\"\\\"\\\"SR-discovered formula for {target_name} (V2 middle-wide shape).\\\"\\\"\\\" \n    x0, x1, x2, x3 = base_size, layer_index, petal_index, opening_degree\n    return {code}\n\"\"\"\n    return func_code\n\n# Generate Python module\nmodule_code = '''#!/usr/bin/env python3\n\"\"\"Auto-generated SR formulas for petal spline V2 control points.\n\nGenerated by Kaggle GPU training.\nFeatures: middle-wide shape, ultra-thin thickness\n\"\"\"\nimport math\n\n'''\n\nfor target, formula in discovered_formulas.items():\n    module_code += formula_to_python(formula, target)\n    module_code += \"\\n\"\n\n# Save to file\nwith open('data/generated/petal_spline_v2_formulas.py', 'w') as f:\n    f.write(module_code)\n\nprint(\"✓ Generated Python module: data/generated/petal_spline_v2_formulas.py\")\nprint(\"\\nGenerated code preview:\")\nprint(module_code[:1500])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test generated formulas (V2)\nimport sys\nsys.path.insert(0, 'data/generated')\nimport petal_spline_v2_formulas as psf\n\n# Test with sample input (larger base_size for V2)\nbase_size = 5.0\nlayer_index = 1  # 0-based\npetal_index = 0\nopening_degree = 0.8\n\nprint(f\"Test input: base_size={base_size}, layer_index={layer_index}, petal_index={petal_index}, opening_degree={opening_degree}\")\nprint()\n\nfor target in targets:\n    func = getattr(psf, f'compute_{target}')\n    value = func(base_size, layer_index, petal_index, opening_degree)\n    print(f\"{target} = {value:.6f}\")\n\n# Verify middle-wide shape\ncp2_x = psf.compute_cp2_x(base_size, layer_index, petal_index, opening_degree)\ncp4_x = psf.compute_cp4_x(base_size, layer_index, petal_index, opening_degree)\ncp1_x = psf.compute_cp1_x(base_size, layer_index, petal_index, opening_degree)\ncp5_x = psf.compute_cp5_x(base_size, layer_index, petal_index, opening_degree)\n\nmid_width = cp4_x - cp2_x\nbase_width = cp5_x - cp1_x\nprint(f\"\\nMiddle-wide verification:\")\nprint(f\"  Mid width: {mid_width:.4f}\")\nprint(f\"  Base width: {base_width:.4f}\")\nprint(f\"  Ratio: {mid_width/base_width:.2f} (should be ~2.0)\")"
  },
  {
   "cell_type": "code",
   "source": "# Train bone_rigging_v4 (4 bones branching structure)\nprint(\"=\"*60)\nprint(\"BONE RIGGING V4 - 4 Bones Branching Structure\")\nprint(\"=\"*60)\n\nbone_df = pd.read_csv('data/processed/bone_rigging_v4.csv')\nprint(f\"Dataset shape: {bone_df.shape}\")\nprint(f\"Features: {list(bone_df.columns[:5])}\")\nprint(f\"Targets: {list(bone_df.columns[5:])}\")\n\n# Features for bone rigging\nbone_features = ['petal_height', 'petal_width', 'opening_degree', 'layer_index', 'curvature_intensity']\nbone_X = bone_df[bone_features].values\n\n# Train key bone parameters (root_end_y, middle_end_y, left_end_x, right_end_x)\nkey_bone_targets = ['bone_root_end_y', 'bone_middle_end_y', 'bone_left_end_x', 'bone_left_end_y', 'bone_right_end_x']\n\nbone_formulas = {}\n\nfor target in key_bone_targets:\n    print(f\"\\nTraining: {target}\")\n    y = bone_df[target].values\n    \n    model = PySRRegressor(\n        niterations=30,\n        binary_operators=[\"+\", \"-\", \"*\", \"/\"],\n        unary_operators=[\"sqrt\"],\n        populations=10,\n        population_size=30,\n        maxsize=15,\n        parsimony=0.003,\n        model_selection=\"best\",\n        verbosity=0,\n    )\n    \n    model.fit(bone_X, y, variable_names=bone_features)\n    formula = str(model.sympy())\n    bone_formulas[target] = formula\n    print(f\"✓ {target} = {formula}\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"Bone Rigging V4 Formulas (4 bones branching):\")\nprint(f\"{'='*60}\")\nfor target, formula in bone_formulas.items():\n    print(f\"{target} = {formula}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit and push back to GitHub (optional)\n",
    "# Requires setting up Git credentials\n",
    "\n",
    "# !git config user.name \"Kaggle Training\"\n",
    "# !git config user.email \"training@kaggle.com\"\n",
    "# !git add data/generated/\n",
    "# !git commit -m \"feat: Add SR-discovered formulas from Kaggle GPU training\"\n",
    "# !git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Increase iterations**: `niterations=200-500` for better formulas\n",
    "2. **Add more operators**: `\"exp\", \"log\", \"pow\"` for complex patterns\n",
    "3. **Train CoT models**: Predict optimal CP count from shape features\n",
    "4. **Export to Aicua_SR**: Download formulas and commit to GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}